server:
  port: 8282
logging:
  level:
    org.springframework.ai.chat.client.advisor.*: DEBUG
    jm.kr.spring.ai.playground.service.*: DEBUG
    org.springframework.ai.mcp: DEBUG

spring:
  threads:
    virtual:
      enabled: true
  application:
    name: spring-ai-playground
  profiles:
    default: mcp, ollama
  ai:
    model:
      chat: ollama
    playground:
      user-home:
      chat:
        system:
          prompt:
  servlet:
    multipart:
      max-file-size: 20MB
      max-request-size: 20MB

---
spring:
  config:
    activate:
      on-profile: ollama
  ai:
    ollama:
      init:
        pull-model-strategy: when_missing
      chat:
        options:
          model: qwen3
      embedding:
        options:
          model: qwen3-embedding:0.6b
    playground:
      chat:
        models:
          - gpt-oss
          - llama3.2
          - mistral
          - qwen3
          - deepseek-r1
          - hf.co/rippertnt/HyperCLOVAX-SEED-Text-Instruct-1.5B-Q4_K_M-GGUF
---
spring:
  config:
    activate:
      on-profile: openai
  ai:
    openai:
      api-key: ${OPENAI_API_KEY}
      chat:
        enabled: false
        options:
          model: o1-mini
    playground:
      chat:
        models:
          - gpt-5-nano
          - gpt-5-mini
          - gpt-5-chat
          - gpt-5
          - gpt-4.1-nano
          - gpt-4.1-mini
          - gpt-4.1
          - o3-mini
          - o3
          - o3-pro

---
spring:
  config:
    activate:
      on-profile: mcp
  ai:
    mcp:
      client:
        type: SYNC
        initialized: false
