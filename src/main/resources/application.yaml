logging:
  level:
    org.springframework.ai.chat.client.advisor.*: DEBUG
    jm.kr.spring.ai.playground.service.*: DEBUG
    org.springframework.ai.mcp: DEBUG

spring:
  threads:
    virtual:
      enabled: true
  application:
    name: spring-ai-playground
  profiles:
    default: mcp, ollama
  ai:
    model:
      chat: ollama
    playground:
      user-home:
      chat:
        system:
          prompt:
  servlet:
    multipart:
      max-file-size: 20MB
      max-request-size: 20MB

---
spring:
  config:
    activate:
      on-profile: ollama
  ai:
    ollama:
      init:
        pull-model-strategy: always
      chat:
        options:
          model: qwen3
      embedding:
        options:
          model: bge-m3
    playground:
      chat:
        models:
          - llama3.2
          - mistral
          - qwen3
          - deepseek-r1
          - hf.co/rippertnt/HyperCLOVAX-SEED-Text-Instruct-1.5B-Q4_K_M-GGUF
---
spring:
  config:
    activate:
      on-profile: openai
  ai:
    openai:
      api-key: ${OPENAI_API_KEY}
      chat:
        enabled: false
        options:
          model: o1-mini
    playground:
      chat:
        models:
          - o1-mini
          - o1
          - gpt-4o
          - o1-preview
          - gpt-4o-mini
          - gpt-3.5-turbo
          - gpt-3.5-turbo-16k
          - gpt-4
          - gpt-4-32k
          - gpt-4-turbo

---
spring:
  config:
    activate:
      on-profile: mcp
  ai:
    mcp:
      client:
        type: SYNC  # MCP Client 타입
        initialized: false
